{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Kubernetes\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we train a Agent to solve a scenario with pods and variable load generated by Apache HTTP server benchmarking tool\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages in order to connect Kubernetes and Prometheus\n",
    "minikube service -n monitoring prometheus-service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install prometheus-api-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from kubernetes import client, config\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "import k8senv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment. \n",
    "We create a Deployment that the agent will assign number of pods, if already exist will send a error (409) \n",
    "Note: The deployments exists even the number of pods is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.load_kube_config()\n",
    "apps_api = client.AppsV1Api()\n",
    "deployment = client.V1Deployment()\n",
    "deployment.api_version = \"apps/v1\"\n",
    "deployment.kind = \"Deployment\"\n",
    "deployment.metadata = client.V1ObjectMeta(name=\"httpdia\")\n",
    "name = \"httpdia\"\n",
    "spec = client.V1DeploymentSpec(\n",
    "    selector=client.V1LabelSelector(match_labels={\"app\":\"httpdia\"}),\n",
    "    template=client.V1PodTemplateSpec(),\n",
    ")\n",
    "container = client.V1Container(\n",
    "    image=\"httpd\",\n",
    "    resources = {\"limits\": {\"cpu\":\"500m\"} , \"requests\": {\"cpu\":\"200m\"}},\n",
    "    name=name, \n",
    ")\n",
    "spec.template.metadata = client.V1ObjectMeta(\n",
    "    name=\"httpdia\",\n",
    "    labels={\"app\":\"httpdia\"},\n",
    ")\n",
    "spec.template.spec = client.V1PodSpec(containers = [container])\n",
    "dep = client.V1Deployment(\n",
    "    metadata=client.V1ObjectMeta(name=name),\n",
    "    spec=spec,\n",
    ")\n",
    "dep.spec.replicas = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    apps_api.create_namespaced_deployment(namespace=\"default\", body=dep)\n",
    "except:\n",
    "    print(\"Pod Existente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the parameter manual and we can validate with\n",
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.spec.replicas = 3\n",
    "changeddeploy= apps_api.replace_namespaced_deployment(name=name, namespace=\"default\", body=dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chech the conection with the enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check number of pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.load_kube_config()\n",
    "v1=client.CoreV1Api()\n",
    "ret=v1.list_namespaced_pod('default',watch=False)\n",
    "pods=ret.items\n",
    "pods_names=[pod.metadata.name for pod in pods]\n",
    "number_pods= 0\n",
    "for pod in pods_names:\n",
    "    if (pod.find(\"httpdia\")>-1):\n",
    "        number_pods = number_pods+1\n",
    "print(\"Number of Pods: \" + str(number_pods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check and read metrics from Prometheus , number of pods from kubernetes and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapse=\"1m\"\n",
    "namespace_kubernetes =\"default\"\n",
    "hostprometheus =\"http://127.0.0.1:55167/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k8senv.check_kuber_prometheus(lapse,namespace_kubernetes,hostprometheus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that change the number of pods.  At each time step, it has one action at its disposal:\n",
    "\n",
    "- `n` - n pods assigned\n",
    "\n",
    "The state space has `9` dimensions and contains Number of Pods assigned, File descriptors, Receive Packets, Transmit Packets, \n",
    "  Dropped Packets, CPU Usage Seconds, CPU Throttled Seconds, Memory Working Bytes, Memory Usage bytes. \n",
    ".  The reward is calculated : score = (1  - (float(dropped_packets)/number_pods) - float(cpu_throttled_seconds)) / number_pods. \n",
    "we penalize cpu throttled cpu and dropped pakets, the score is divided by number of pods in order to reward the minimal use of pods.\n",
    "\n",
    "Run the code cell below to print some information about the environment. ( check that is generating load to the pods using CreatePodLoadGenerator Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the enviroment\n",
    "initialpods = 10\n",
    "#env_info = k8senv.step(initialpods,hostprometheus,lapse,namespace_kubernetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state = env_info['vector_observations']            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "rangenumberpodsrandom = 30\n",
    "#print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivocarga=\"cargapod.csv\"\n",
    "dataloaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "k8senv.enviroment(archivocarga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(archivocarga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pods  file_descriptors  receive_packets  transmit_packets  \\\n",
      "0      10.0               0.0              0.0               0.0   \n",
      "1      10.0               0.0              0.0               0.0   \n",
      "2      10.0               0.0              0.0               0.0   \n",
      "3      10.0               0.0              0.0               0.0   \n",
      "4      10.0               0.0              0.0               0.0   \n",
      "...     ...               ...              ...               ...   \n",
      "14650  20.0             308.3           7219.0            5033.7   \n",
      "14651  20.0             307.6           7046.1            4859.8   \n",
      "14652  20.0             296.5           6769.0            4585.5   \n",
      "14653  20.0             270.3           5923.1            3991.4   \n",
      "14654  20.0             270.3           5923.1            3991.4   \n",
      "\n",
      "       dropped_packets  cpu_usage_seconds  cpu_throttled_seconds  \\\n",
      "0                  0.0           0.000754                    0.0   \n",
      "1                  0.0           0.000650                    0.0   \n",
      "2                  0.0           0.000687                    0.0   \n",
      "3                  0.0           0.000688                    0.0   \n",
      "4                  0.0           0.000659                    0.0   \n",
      "...                ...                ...                    ...   \n",
      "14650              0.0           1.162627                    0.0   \n",
      "14651              0.0           1.146153                    0.0   \n",
      "14652              0.0           1.132761                    0.0   \n",
      "14653              0.0           1.016379                    0.0   \n",
      "14654              0.0           1.016264                    0.0   \n",
      "\n",
      "       memory_working_bytes  memory_usage_bytes    carga  \\\n",
      "0                       0.0                38.0   1000.0   \n",
      "1                       0.0                38.0   1000.0   \n",
      "2                       0.0                38.0   1000.0   \n",
      "3                       0.0                38.0   2000.0   \n",
      "4                       0.0                38.0   2000.0   \n",
      "...                     ...                 ...      ...   \n",
      "14650           437795648.8                39.0  17000.0   \n",
      "14651           441291977.8                39.0  18000.0   \n",
      "14652           444741600.6                39.0  19000.0   \n",
      "14653           409424631.3                39.0  20000.0   \n",
      "14654           409376598.7                39.0  20000.0   \n",
      "\n",
      "                            fecha  \n",
      "0      2021-05-31 20:00:01.421680  \n",
      "1      2021-05-31 20:00:02.915908  \n",
      "2      2021-05-31 20:00:03.514198  \n",
      "3      2021-05-31 20:00:04.623678  \n",
      "4      2021-05-31 20:00:05.702287  \n",
      "...                           ...  \n",
      "14650  2021-06-01 00:05:33.848677  \n",
      "14651  2021-06-01 00:05:34.996178  \n",
      "14652  2021-06-01 00:05:36.163436  \n",
      "14653  2021-06-01 00:05:37.306974  \n",
      "14654  2021-06-01 00:05:37.400990  \n",
      "\n",
      "[14655 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "proceso con archivo\n",
      " action: 20 reward:-2.32\n",
      "Score: -4.64\n"
     ]
    }
   ],
   "source": [
    "max_t = 1\n",
    "t=0\n",
    "\n",
    "while True:\n",
    "    t=t+1\n",
    "    action = np.random.randint(rangenumberpodsrandom)                         # select an action\n",
    "    \n",
    "    ## next two lines is comented when using loadfile\n",
    "    #env_info = k8senv.step(action,hostprometheus,lapse,namespace_kubernetes, archivocarga)  # send the action to the environment\n",
    "    #time.sleep(4)\n",
    "    env_info = k8senv.step(action,hostprometheus,lapse,namespace_kubernetes)  # send the action to the environment\n",
    "    next_state = env_info['vector_observations']                              # get the next state\n",
    "    reward = env_info['rewards'][0]                                           # get the reward\n",
    "    done = env_info['local_done'][0]                                             # see if episode has finished\n",
    "    if t >= max_t :\n",
    "        done=True\n",
    "    score += reward                                                           # update the score\n",
    "    state = next_state                                                        # roll over the state to next time step\n",
    "    \n",
    "    print(\" action: \" + str(action) +\" reward:\" + str(reward) )\n",
    "    if done:                                                                  # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Agent DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=9, action_size=20, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=5, max_t=100, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    initialaction=10\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        # The reset is step too\n",
    "        env_info = k8senv.step(initialaction,hostprometheus,lapse,namespace_kubernetes, archivocarga)\n",
    "        state = np.array(env_info['vector_observations'])\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            action = action.astype(int)\n",
    "            action= action.item()\n",
    "            print(\"Iteracion:\"+str(t)+\" Accion:\"+str(action)+\" Score:\"+str(score))\n",
    "            ## Next 3 lines is comented when using load file\n",
    "            #env_info = k8senv.step(action,hostprometheus,lapse,namespace_kubernetes, archivocarga)\n",
    "            #print(env_info['vector_observations'])\n",
    "            #time.sleep(2)\n",
    "            env_info = k8senv.step(action,hostprometheus,lapse,namespace_kubernetes, archivocarga)\n",
    "            print(env_info['vector_observations'])\n",
    "            next_state =  np.array(env_info['vector_observations'])\n",
    "            reward = env_info['rewards'][0] \n",
    "            done = False\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if t >= max_t :\n",
    "                done=True            \n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_project1.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint_project1.pth'))\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    action = agent.act(state).item()\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
